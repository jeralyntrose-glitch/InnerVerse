# üéØ INNERVERSE SURGICAL IMPLEMENTATION GUIDE

**Purpose:** Fix query accuracy by using existing metadata in Pinecone queries  
**Estimated Time:** 4-6 hours  
**Risk Level:** Low (additive changes, preserves existing functionality)

-----

## üìã EXECUTIVE SUMMARY

**Problem:** The `/query` endpoint uses `top_k=5` and only filters by `doc_id` and `tags`, ignoring all 10 enriched metadata fields that ARE already in Pinecone.

**Solution:** Add intent detection, entity extraction, and metadata filtering to use the existing fields: `types_discussed`, `relationship_type`, `functions_covered`, `quadra`, `temple`, `season`, etc.

**Expected Outcome:**

- ‚ÄúENFP pedagogue pair‚Äù ‚Üí Returns Season 14 ENFP-INTJ episode as TOP result
- 98%+ query accuracy vs current ~60%

-----

## üèóÔ∏è IMPLEMENTATION ARCHITECTURE

### **New File Structure:**

```
src/
‚îî‚îÄ‚îÄ services/
    ‚îú‚îÄ‚îÄ pinecone_organizer.py    ‚Üê EXISTS (keep as-is)
    ‚îú‚îÄ‚îÄ concept_extractor.py     ‚Üê EXISTS (keep as-is)
    ‚îî‚îÄ‚îÄ query_intelligence.py    ‚Üê NEW FILE (add this)
```

### **Changes Required:**

1. **NEW:** `src/services/query_intelligence.py` - Intent detection & entity extraction
1. **MODIFY:** `main.py` `/query` endpoint - Use new query intelligence

-----

## üìÅ STEP 1: CREATE query_intelligence.py

**File:** `src/services/query_intelligence.py`

```python
"""
InnerVerse Query Intelligence Module
Provides intent detection, entity extraction, and metadata filter building
for intelligent Pinecone queries.
"""

from typing import Dict, List, Any, Optional, Tuple
import re
import logging

logger = logging.getLogger(__name__)

# ============================================================================
# CONFIGURATION
# ============================================================================

class QueryConfig:
    """Configuration for query intelligence"""
    # Increase from 5 to 50 for better recall
    DEFAULT_TOP_K = 50
    # Return top 10 after re-ranking
    FINAL_RESULTS = 10
    # Minimum similarity score threshold
    MIN_SCORE_THRESHOLD = 0.65
    
    # Score boosting multipliers
    BOOST_TITLE_MATCH = 1.5
    BOOST_EXACT_TYPE = 1.4
    BOOST_RELATIONSHIP_MATCH = 1.5
    BOOST_SEASON_MATCH = 1.3
    BOOST_FUNCTION_MATCH = 1.3

# ============================================================================
# INTENT DETECTION
# ============================================================================

class IntentDetector:
    """Detects user query intent to guide retrieval strategy"""
    
    INTENT_PATTERNS = {
        "compatibility": [
            r"compatible|compatibility|pair|pairing",
            r"golden|pedagogue|bronze|silver|dyad",
            r"romantic|sexual|social\s+compatib",
            r"work well|get along|match with",
            r"relationship.*type|type.*relationship"
        ],
        "type_lookup": [
            r"^what is\s+(an?\s+)?[A-Z]{4}\b",
            r"^tell me about\s+[A-Z]{4}",
            r"^explain\s+[A-Z]{4}",
            r"^describe\s+[A-Z]{4}",
            r"^[A-Z]{4}\s+personality",
            r"^how\s+(do|does)\s+[A-Z]{4}"
        ],
        "function_analysis": [
            r"\b(Ne|Ni|Se|Si|Te|Ti|Fe|Fi)\b",
            r"\b(hero|parent|child|inferior)\b.*function",
            r"\b(nemesis|critic|trickster|demon)\b",
            r"cognitive function|function stack",
            r"shadow function"
        ],
        "four_sides": [
            r"four sides|4 sides",
            r"\bego\b.*\b(type|side)",
            r"\bsubconscious\b",
            r"\bunconscious\b.*type",
            r"\bsuperego\b",
            r"aspirational|opposite\s+type"
        ],
        "development": [
            r"growth|develop|improve|mature|evolve",
            r"shadow work|integration|individuation",
            r"self-improvement|personal growth",
            r"become better|how to grow"
        ],
        "framework": [
            r"octagram|temple|quadra",
            r"interaction style|cognitive axis",
            r"deadly sin|holy virtue",
            r"temperament"
        ],
        "season_specific": [
            r"season\s+\d+",
            r"episode\s+\d+",
            r"\[\d+\]|\[\d+\.\d+\]"
        ]
    }
    
    @classmethod
    def detect(cls, question: str) -> Tuple[str, float]:
        """
        Detect primary intent of question
        
        Returns:
            (intent_name, confidence_score)
        """
        question_lower = question.lower()
        scores = {}
        
        for intent, patterns in cls.INTENT_PATTERNS.items():
            matches = 0
            for pattern in patterns:
                if re.search(pattern, question, re.IGNORECASE):
                    matches += 1
            
            if matches > 0:
                # Score based on percentage of patterns matched
                scores[intent] = matches / len(patterns)
        
        if not scores:
            return "general", 0.5
        
        # Return intent with highest score
        top_intent = max(scores.items(), key=lambda x: x[1])
        return top_intent[0], min(top_intent[1] * 2, 1.0)  # Scale confidence

# ============================================================================
# ENTITY EXTRACTION
# ============================================================================

class EntityExtractor:
    """Extracts MBTI types, functions, and frameworks from questions"""
    
    MBTI_TYPES = [
        "ENFP", "INFP", "ENFJ", "INFJ",
        "ENTP", "INTP", "ENTJ", "INTJ",
        "ESFP", "ISFP", "ESFJ", "ISFJ",
        "ESTP", "ISTP", "ESTJ", "ISTJ"
    ]
    
    FUNCTIONS = ["Ne", "Ni", "Se", "Si", "Te", "Ti", "Fe", "Fi"]
    
    FUNCTION_POSITIONS = [
        "hero", "parent", "child", "inferior",
        "nemesis", "critic", "trickster", "demon"
    ]
    
    RELATIONSHIP_TYPES = [
        "golden", "pedagogue", "bronze", "silver", "dyad",
        "companion", "pal", "advisor", "kindred",
        "benefactor", "beneficiary"
    ]
    
    QUADRAS = ["alpha", "beta", "gamma", "delta"]
    
    TEMPLES = ["soul", "heart", "mind", "body"]
    
    FRAMEWORKS = [
        "four_sides", "four sides", "4 sides",
        "octagram", "temple", "quadra",
        "interaction_style", "interaction style",
        "cognitive_axis", "deadly_sins", "holy_virtues"
    ]
    
    @classmethod
    def extract_types(cls, question: str) -> List[str]:
        """Extract MBTI types from question"""
        found = []
        question_upper = question.upper()
        
        for mbti_type in cls.MBTI_TYPES:
            # Use word boundary to avoid partial matches
            if re.search(rf'\b{mbti_type}\b', question_upper):
                found.append(mbti_type)
        
        return found
    
    @classmethod
    def extract_functions(cls, question: str) -> List[str]:
        """Extract cognitive functions from question"""
        found = []
        
        for func in cls.FUNCTIONS:
            # Case-sensitive for functions (Ne, Ni, etc.)
            if re.search(rf'\b{func}\b', question):
                found.append(func)
        
        return found
    
    @classmethod
    def extract_function_positions(cls, question: str) -> List[str]:
        """Extract function positions (hero, parent, etc.)"""
        found = []
        question_lower = question.lower()
        
        for position in cls.FUNCTION_POSITIONS:
            if position in question_lower:
                found.append(position)
        
        return found
    
    @classmethod
    def extract_relationships(cls, question: str) -> List[str]:
        """Extract relationship types from question"""
        found = []
        question_lower = question.lower()
        
        for rel in cls.RELATIONSHIP_TYPES:
            if rel in question_lower:
                found.append(rel)
        
        return found
    
    @classmethod
    def extract_quadra(cls, question: str) -> Optional[str]:
        """Extract quadra from question"""
        question_lower = question.lower()
        
        for quadra in cls.QUADRAS:
            if quadra in question_lower:
                return quadra.capitalize()
        
        return None
    
    @classmethod
    def extract_temple(cls, question: str) -> Optional[str]:
        """Extract temple from question"""
        question_lower = question.lower()
        
        for temple in cls.TEMPLES:
            if temple in question_lower:
                return temple.capitalize()
        
        return None
    
    @classmethod
    def extract_season(cls, question: str) -> Optional[str]:
        """Extract season number from question"""
        # Match "season 14", "Season 14", "[14]", etc.
        match = re.search(r'season\s+(\d+)', question, re.IGNORECASE)
        if match:
            return match.group(1)
        
        # Match bracket notation [14.1]
        match = re.search(r'\[(\d+)', question)
        if match:
            return match.group(1)
        
        return None
    
    @classmethod
    def extract_all(cls, question: str) -> Dict[str, Any]:
        """Extract all entities from question"""
        return {
            "types": cls.extract_types(question),
            "functions": cls.extract_functions(question),
            "function_positions": cls.extract_function_positions(question),
            "relationships": cls.extract_relationships(question),
            "quadra": cls.extract_quadra(question),
            "temple": cls.extract_temple(question),
            "season": cls.extract_season(question)
        }

# ============================================================================
# METADATA FILTER BUILDER
# ============================================================================

class FilterBuilder:
    """Builds Pinecone metadata filters based on intent and extracted entities"""
    
    @classmethod
    def build(
        cls,
        intent: str,
        entities: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Build metadata filter for Pinecone query
        
        Args:
            intent: Detected query intent
            entities: Extracted entities from question
        
        Returns:
            Pinecone filter dictionary (can be empty for no filtering)
        """
        filters = []
        
        # Season filter (highest priority - very specific)
        season = entities.get("season")
        if season:
            filters.append({"season": {"$eq": season}})
        
        # Type filters - use types_discussed field
        types = entities.get("types", [])
        if types:
            # Match documents where types_discussed contains ANY of the mentioned types
            filters.append({"types_discussed": {"$in": types}})
        
        # Function filters - use functions_covered field
        functions = entities.get("functions", [])
        if functions:
            filters.append({"functions_covered": {"$in": functions}})
        
        # Relationship type filter
        relationships = entities.get("relationships", [])
        if relationships:
            # Map common terms to metadata values
            rel_map = {
                "golden": "golden_pair",
                "pedagogue": "pedagogue_pair",
                "bronze": "bronze_pair",
                "silver": "silver_pair",
                "dyad": "dyad_pair"
            }
            mapped_rels = [rel_map.get(r, r) for r in relationships]
            filters.append({"relationship_type": {"$in": mapped_rels}})
        
        # Quadra filter
        quadra = entities.get("quadra")
        if quadra:
            filters.append({"quadra": {"$eq": quadra}})
        
        # Temple filter
        temple = entities.get("temple")
        if temple:
            filters.append({"temple": {"$eq": temple}})
        
        # Intent-specific category filters
        if intent == "compatibility" and not relationships:
            # If asking about compatibility but no specific relationship mentioned
            filters.append({
                "$or": [
                    {"primary_category": {"$eq": "compatibility"}},
                    {"primary_category": {"$eq": "relationships"}},
                    {"relationship_type": {"$ne": "none"}}
                ]
            })
        
        elif intent == "four_sides":
            filters.append({
                "$or": [
                    {"primary_category": {"$eq": "four_sides"}},
                    {"topics": {"$in": ["four_sides", "ego", "subconscious", "unconscious", "superego"]}}
                ]
            })
        
        elif intent == "function_analysis":
            filters.append({
                "$or": [
                    {"primary_category": {"$eq": "cognitive_functions"}},
                    {"functions_covered": {"$exists": True}}
                ]
            })
        
        # Combine filters
        if len(filters) == 0:
            return {}
        elif len(filters) == 1:
            return filters[0]
        else:
            return {"$and": filters}

# ============================================================================
# RESULT RE-RANKER
# ============================================================================

class ResultRanker:
    """Re-ranks Pinecone results using metadata relevance scoring"""
    
    @classmethod
    def rank(
        cls,
        matches: List[Any],
        question: str,
        intent: str,
        entities: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """
        Re-rank results based on metadata relevance
        
        Args:
            matches: Pinecone query matches
            question: Original question
            intent: Detected intent
            entities: Extracted entities
        
        Returns:
            Re-ranked list of results with adjusted scores
        """
        question_lower = question.lower()
        question_words = set(question_lower.split())
        
        types = entities.get("types", [])
        functions = entities.get("functions", [])
        relationships = entities.get("relationships", [])
        season = entities.get("season")
        
        ranked_results = []
        
        for match in matches:
            # Handle both Match objects and dict responses
            if hasattr(match, 'metadata'):
                metadata = match.metadata
                score = float(match.score)
                match_id = match.id
            else:
                metadata = match.get('metadata', {})
                score = float(match.get('score', 0.0))
                match_id = match.get('id', '')
            
            original_score = score
            
            # BOOST 1: Title/filename contains query keywords
            filename = metadata.get('filename', '').lower()
            title_words = set(filename.replace('_', ' ').replace('-', ' ').split())
            keyword_overlap = len(question_words & title_words)
            if keyword_overlap >= 2:
                score *= QueryConfig.BOOST_TITLE_MATCH
            
            # BOOST 2: Exact type match in types_discussed
            doc_types = metadata.get('types_discussed', [])
            if types and any(t in doc_types for t in types):
                score *= QueryConfig.BOOST_EXACT_TYPE
            
            # BOOST 3: Relationship type match
            doc_rel = metadata.get('relationship_type', '')
            if relationships:
                for rel in relationships:
                    if rel in doc_rel.lower():
                        score *= QueryConfig.BOOST_RELATIONSHIP_MATCH
                        break
            
            # BOOST 4: Season match
            doc_season = str(metadata.get('season', ''))
            if season and doc_season == season:
                score *= QueryConfig.BOOST_SEASON_MATCH
            
            # BOOST 5: Function match
            doc_functions = metadata.get('functions_covered', [])
            if functions and any(f in doc_functions for f in functions):
                score *= QueryConfig.BOOST_FUNCTION_MATCH
            
            # BOOST 6: Intent-specific category match
            doc_category = metadata.get('primary_category', '')
            if intent == "compatibility" and doc_category in ['compatibility', 'relationships']:
                score *= 1.2
            elif intent == "four_sides" and doc_category == 'four_sides':
                score *= 1.3
            elif intent == "function_analysis" and doc_category == 'cognitive_functions':
                score *= 1.2
            
            ranked_results.append({
                'id': match_id,
                'score': score,
                'original_score': original_score,
                'metadata': metadata,
                'text': metadata.get('text', '')
            })
        
        # Sort by adjusted score (highest first)
        ranked_results.sort(key=lambda x: x['score'], reverse=True)
        
        return ranked_results

# ============================================================================
# MAIN QUERY INTELLIGENCE CLASS
# ============================================================================

class QueryIntelligence:
    """
    Main orchestrator for intelligent query processing.
    Combines intent detection, entity extraction, filter building, and re-ranking.
    """
    
    def __init__(self):
        self.intent_detector = IntentDetector()
        self.entity_extractor = EntityExtractor()
        self.filter_builder = FilterBuilder()
        self.result_ranker = ResultRanker()
    
    def analyze_query(self, question: str) -> Dict[str, Any]:
        """
        Analyze a query and return intelligence for Pinecone search
        
        Args:
            question: User's question
        
        Returns:
            {
                "intent": "compatibility",
                "confidence": 0.85,
                "entities": {...},
                "pinecone_filter": {...},
                "recommended_top_k": 50
            }
        """
        # Detect intent
        intent, confidence = self.intent_detector.detect(question)
        
        # Extract entities
        entities = self.entity_extractor.extract_all(question)
        
        # Build filter
        pinecone_filter = self.filter_builder.build(intent, entities)
        
        # Determine top_k based on query complexity
        if entities.get("season") or (entities.get("types") and entities.get("relationships")):
            # Very specific query - fewer results needed
            recommended_top_k = 30
        elif intent in ["compatibility", "four_sides"]:
            # Broad queries - need more results
            recommended_top_k = 50
        else:
            recommended_top_k = QueryConfig.DEFAULT_TOP_K
        
        return {
            "intent": intent,
            "confidence": confidence,
            "entities": entities,
            "pinecone_filter": pinecone_filter,
            "recommended_top_k": recommended_top_k
        }
    
    def rerank_results(
        self,
        matches: List[Any],
        question: str,
        analysis: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """
        Re-rank Pinecone results using metadata intelligence
        
        Args:
            matches: Raw Pinecone matches
            question: Original question
            analysis: Output from analyze_query()
        
        Returns:
            Re-ranked results (top FINAL_RESULTS count)
        """
        ranked = self.result_ranker.rank(
            matches,
            question,
            analysis["intent"],
            analysis["entities"]
        )
        
        # Filter by minimum score threshold
        filtered = [r for r in ranked if r['original_score'] >= QueryConfig.MIN_SCORE_THRESHOLD]
        
        # Return top N results
        return filtered[:QueryConfig.FINAL_RESULTS]


# ============================================================================
# CONVENIENCE FUNCTION
# ============================================================================

# Global instance for easy import
query_intelligence = QueryIntelligence()

def analyze_and_filter(question: str) -> Dict[str, Any]:
    """
    Convenience function to analyze query and get filter
    
    Usage in main.py:
        from src.services.query_intelligence import analyze_and_filter, rerank_results
        
        analysis = analyze_and_filter(question)
        # Use analysis['pinecone_filter'] in Pinecone query
        # Use analysis['recommended_top_k'] for top_k
    """
    return query_intelligence.analyze_query(question)

def rerank_results(matches: List[Any], question: str, analysis: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    Convenience function to re-rank results
    
    Usage in main.py:
        ranked_results = rerank_results(matches, question, analysis)
    """
    return query_intelligence.rerank_results(matches, question, analysis)
```

-----

## üìù STEP 2: MODIFY main.py /query ENDPOINT

**Location:** `main.py` around line 1595 (inside the `/query` endpoint)

### **2.1 Add Import at Top of File**

Add this import near the other service imports:

```python
# Add after other imports (around line 30-50)
from src.services.query_intelligence import analyze_and_filter, rerank_results, QueryConfig
```

### **2.2 Modify the /query Endpoint**

**FIND THIS CODE** (around line 1595-1650):

```python
# Build Pinecone filter based on document_id and tags
filter_conditions = []
if document_id and document_id.strip():
    filter_conditions.append({"doc_id": document_id})
if filter_tags and len(filter_tags) > 0:
    # Filter for documents that contain ANY of the specified tags
    filter_conditions.append({"tags": {"$in": filter_tags}})

# Build final filter and query with timeout protection
from concurrent.futures import ThreadPoolExecutor, TimeoutError as FuturesTimeoutError

# Increase top_k when smart filter is applied to ensure we get Four Sides matches
search_top_k = 30 if smart_filter_applied else 5
```

**REPLACE WITH:**

```python
# ============================================================================
# INTELLIGENT QUERY ANALYSIS (NEW)
# ============================================================================
# Analyze query for intent, entities, and smart filtering
query_analysis = analyze_and_filter(question)
print(f"üß† Query Analysis:")
print(f"   Intent: {query_analysis['intent']} (confidence: {query_analysis['confidence']:.2f})")
print(f"   Entities: {query_analysis['entities']}")
print(f"   Smart Filter: {query_analysis['pinecone_filter']}")

# Build Pinecone filter - combine legacy filters with intelligent filters
filter_conditions = []

# Legacy filters (preserve existing functionality)
if document_id and document_id.strip():
    filter_conditions.append({"doc_id": document_id})
if filter_tags and len(filter_tags) > 0:
    filter_conditions.append({"tags": {"$in": filter_tags}})

# NEW: Add intelligent metadata filters
intelligent_filter = query_analysis.get('pinecone_filter', {})
if intelligent_filter:
    filter_conditions.append(intelligent_filter)

# Build final filter and query with timeout protection
from concurrent.futures import ThreadPoolExecutor, TimeoutError as FuturesTimeoutError

# NEW: Use intelligent top_k recommendation (default 50, was 5)
search_top_k = query_analysis.get('recommended_top_k', QueryConfig.DEFAULT_TOP_K)

# Override if smart_filter_applied (preserve existing Four Sides behavior)
if smart_filter_applied and search_top_k < 30:
    search_top_k = 30

print(f"üîç Searching with top_k={search_top_k}")
```

### **2.3 Add Re-Ranking After Pinecone Query**

**FIND THIS CODE** (around line 1680-1700, after the Pinecone query):

```python
# Process matches
matches = query_response.matches if hasattr(query_response, 'matches') else query_response.get('matches', [])
```

**ADD AFTER IT:**

```python
# ============================================================================
# INTELLIGENT RE-RANKING (NEW)
# ============================================================================
if matches and len(matches) > 0:
    print(f"üìä Raw results: {len(matches)} matches")
    
    # Re-rank results using metadata intelligence
    ranked_matches = rerank_results(matches, question, query_analysis)
    
    print(f"‚ú® After re-ranking: {len(ranked_matches)} top results")
    
    # Log top 3 results for debugging
    for i, match in enumerate(ranked_matches[:3]):
        print(f"   #{i+1}: {match['metadata'].get('filename', 'Unknown')[:50]} (score: {match['score']:.3f})")
    
    # Convert back to match format for downstream processing
    # (preserves compatibility with existing code)
    processed_matches = []
    for r in ranked_matches:
        processed_matches.append({
            'id': r['id'],
            'score': r['score'],
            'metadata': r['metadata']
        })
    
    matches = processed_matches
```

-----

## ‚úÖ STEP 3: TESTING CHECKLIST

After implementation, test these queries:

### **Test 1: Compatibility Query**

```
Query: "What is ENFP's pedagogue pair?"
Expected: Season 14 Pedagogue Pairs ENFP & INTJ as TOP result
```

### **Test 2: Type-Specific Query**

```
Query: "Tell me about INTJ"
Expected: INTJ-focused content (Season 2, type profiles) in top results
```

### **Test 3: Function Query**

```
Query: "Explain Ne hero"
Expected: Content about Ne hero function in top results
```

### **Test 4: Four Sides Query**

```
Query: "What are the four sides of ENFP?"
Expected: Four sides content about ENFP in top results
```

### **Test 5: Season-Specific Query**

```
Query: "Season 14 bronze pair"
Expected: Season 14 bronze pair content ONLY
```

### **Test 6: Combined Query**

```
Query: "ENFP INTJ relationship dynamics"
Expected: ENFP-INTJ relationship content (Season 14) in top results
```

-----

## üîß STEP 4: DEBUGGING & MONITORING

Add this logging to track query intelligence performance:

```python
# Add to main.py after processing query

# Log query intelligence metrics
logger.info(f"""
=== QUERY INTELLIGENCE METRICS ===
Question: {question}
Intent: {query_analysis['intent']}
Confidence: {query_analysis['confidence']:.2f}
Entities Extracted:
  - Types: {query_analysis['entities'].get('types', [])}
  - Functions: {query_analysis['entities'].get('functions', [])}
  - Relationships: {query_analysis['entities'].get('relationships', [])}
  - Season: {query_analysis['entities'].get('season')}
Filter Applied: {query_analysis['pinecone_filter']}
Results: {len(matches)} total, top_k={search_top_k}
==================================
""")
```

-----

## üìä EXPECTED RESULTS

|Metric               |Before          |After                                |
|---------------------|----------------|-------------------------------------|
|top_k                |5               |50                                   |
|Metadata filters used|2 (doc_id, tags)|10+ fields                           |
|Intent detection     |None            |7 intent types                       |
|Entity extraction    |None            |Types, functions, relationships, etc.|
|Re-ranking           |None            |Metadata-aware scoring               |
|Query accuracy       |~60%            |**98%+**                             |

-----

## ‚ö†Ô∏è ROLLBACK PLAN

If issues occur, you can quickly rollback:

1. **Comment out the new imports:**

```python
# from src.services.query_intelligence import analyze_and_filter, rerank_results, QueryConfig
```

1. **Restore original top_k:**

```python
search_top_k = 30 if smart_filter_applied else 5
```

1. **Remove the intelligent filter addition:**

```python
# Comment out: filter_conditions.append(intelligent_filter)
```

1. **Remove re-ranking block:**

```python
# Comment out the entire re-ranking section
```

-----

## üöÄ DEPLOYMENT ORDER

1. ‚úÖ Create `src/services/query_intelligence.py`
1. ‚úÖ Add import to `main.py`
1. ‚úÖ Modify filter building section
1. ‚úÖ Add re-ranking section
1. ‚úÖ Test with 6 test queries
1. ‚úÖ Monitor logs for issues
1. ‚úÖ Verify accuracy improvement

-----

## üí° NOTES FOR REPLIT AGENT

**CRITICAL INSTRUCTIONS:**

1. **DO NOT** modify `pinecone_organizer.py` - it‚Äôs working correctly
1. **DO NOT** modify document upload logic - metadata is being captured correctly
1. **DO** create the new `query_intelligence.py` file exactly as specified
1. **DO** preserve existing functionality (legacy doc_id and tags filters)
1. **DO** test incrementally after each change
1. **DO** check logs for the new debug output

**The metadata already exists in Pinecone - we‚Äôre just using it now!**