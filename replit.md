# Overview

This project is a FastAPI-based PDF Q&A application designed to provide intelligent answers from uploaded PDF documents.

# Recent Changes (October 15, 2025)

## YouTube Transcription Production Fix (Latest)
- ✅ **Fixed ffmpeg missing in production** - Changed deployment from Autoscale to VM to include Nix packages
- ✅ **VM deployment includes system packages** - VM deployments include all Nix system packages (ffmpeg) in production
- ✅ **Added ffmpeg detection** - Backend automatically finds and specifies ffmpeg location to yt-dlp
- ✅ **YouTube transcription now works in production** - Must Republish to get the fix

## Mobile UI Enhancements
- ✅ **Compact branding** - Adjusted brain icon (70px), title (24px), and tagline (13px) sizes for mobile
- ✅ **Thinner progress bars** - Reduced to 6px height on mobile for cleaner look
- ✅ **Fixed chat bubble** - Proper width constraints and positioning for mobile devices
- ✅ **Cancel button improvements** - Reduced to half size, moved down to prevent overlap It features a modern web interface with drag-and-drop upload capabilities, processes documents by chunking and embedding their content, stores these embeddings in Pinecone, and leverages OpenAI's GPT models for answering user queries based on the document content. The application aims to offer an intuitive user experience for document interaction and knowledge retrieval, including the ability to transcribe YouTube videos into searchable PDFs and generate document reports.

# User Preferences

Preferred communication style: Simple, everyday language.

# System Architecture

## Frontend Architecture
- **Interface**: Single-page application with a modern, glassmorphic UI, animated SVG brain icon, and a purple gradient theme.
- **Theme System**: Light/Dark mode toggle with persistence via localStorage.
- **Upload Flow**: Supports drag-and-drop PDF uploads, Google Drive integration, and YouTube video transcription to PDF. Progress tracking and real-time status updates are provided for all uploads.
- **Chat Flow**: Integrates a chat interface that allows users to ask questions about uploaded documents, with answers generated by GPT models.
- **Features**: Auto-clipboard copy for document IDs, responsive design for mobile, and various UI enhancements for user interaction.

## Backend Architecture
- **Framework**: FastAPI with asynchronous operations.
- **Runtime**: Python with Uvicorn ASGI server.
- **Design Pattern**: Stateless API where the frontend manages `document_id` and the backend uses it for Pinecone queries.

## Document Processing Pipeline
- **PDF Parsing**: Uses PyPDF2 for text extraction from PDFs.
- **Text Chunking**: Employs LangChain's `RecursiveCharacterTextSplitter` to break documents into overlapping chunks (1000 characters with 200 character overlap) to maintain context.
- **YouTube Transcription**: Utilizes `yt-dlp` for audio extraction from YouTube videos, OpenAI Whisper API for transcription, and ReportLab for PDF generation, supporting videos of any length through smart chunking.

## Vector Storage Strategy
- **Database**: Pinecone vector database (index: "mbti-knowledge") for storing document embeddings.
- **Query Strategy**: Filters by `document_id` to ensure queries are answered from the specified document's content.

## Embedding Generation
- **Provider**: OpenAI API (`text-embedding-ada-002` model) for generating embeddings.
- **Performance**: Embeddings are batch processed before upserting to Pinecone.

## API Structure
- **Upload**: `POST /upload` (multipart/form-data) and `POST /upload-base64` (JSON) for PDF uploads.
- **Query**: `POST /query` for document-specific Q&A.
- **YouTube Transcription**: `POST /transcribe-youtube` for converting YouTube videos to searchable PDFs.
- **Document Report**: `GET /documents/report` for CSV export of uploaded documents.
- **Delete Document**: `DELETE /documents/{document_id}` for removing document data from Pinecone.
- **Static Files**: Serves frontend assets and documentation (`/docs` for Swagger UI).
- **CORS**: Enabled for all origins.

## Configuration Management
- **Environment Variables**: API keys (OPENAI_API_KEY, PINECONE_API_KEY, PINECONE_INDEX) are managed via Replit Secrets.
- **Client Initialization**: Lazy initialization pattern is used for API clients.

# External Dependencies

## Vector Database
- **Pinecone**: Cloud-based vector database for storing and querying embeddings.

## AI/ML Services
- **OpenAI API**: Used for text embeddings (text-embedding-ada-002), GPT-3.5-turbo for Q&A, and Whisper API for audio transcription.

## Document Processing
- **PyPDF2**: For PDF parsing and text extraction.
- **LangChain**: For text splitting utilities.
- **yt-dlp**: For downloading audio from YouTube videos.
- **OpenAI Whisper API**: For transcribing audio.
- **ReportLab**: For generating formatted PDFs from transcriptions.

## Web Framework
- **FastAPI**: Python web framework.
- **Uvicorn**: ASGI server.
- **Pydantic**: Data validation.

## Integrations
- **Google Drive Picker API**: For seamless integration with Google Drive for file selection.
- **ffmpeg**: System dependency for audio processing with `yt-dlp`.