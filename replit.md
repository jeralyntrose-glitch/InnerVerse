# Overview

This is a FastAPI-based PDF Q&A application with a modern web interface that allows users to upload PDF documents, processes them into chunks, stores them in Pinecone vector database, and enables querying the documents using OpenAI's GPT for intelligent answers based on document content. The app features both a drag-and-drop upload interface and an integrated chat system for asking questions about uploaded documents.

# Recent Changes (October 14, 2025)

## Google Drive Integration (Custom Picker)
- ‚úÖ Built custom Google Drive file picker (no Google Cloud Console setup required)
- ‚úÖ Blue "üìÅ Google Drive" button opens popup window with your Drive PDF files
- ‚úÖ Multi-select support - choose multiple PDFs at once
- ‚úÖ Shows file names and sizes in clean, searchable list
- ‚úÖ Automatic download and processing with same progress tracking
- ‚úÖ Backend endpoints: /api/gdrive-list-pdfs, /api/gdrive-download/{file_id}
- ‚úÖ Uses Replit Google Drive connector for seamless OAuth authentication

## UI Fixes & Enhancements
- ‚úÖ Fixed dropdown bug: now closes when clicking outside or toggling again
- ‚úÖ Added click-outside-to-close functionality for document dropdown
- ‚úÖ Added horizontal scrolling to dropdown (overflow-x: auto)
- ‚úÖ Enhanced copy buttons to include Filename, Document ID, and Timestamp in tab-separated format
- ‚úÖ "Copy" button copies in order: PDF Title ‚Üí Document ID ‚Üí Timestamp (for Google Sheets columns)
- ‚úÖ "Copy All IDs" button copies all documents with filename, ID, and date (each in separate columns)
- ‚úÖ Added cancel upload feature with red "‚úï Cancel" button that appears during uploads
- ‚úÖ Cancel button aborts all ongoing fetch requests using AbortController API
- ‚úÖ Cancelled uploads are marked with "(Cancelled)" label and error styling
- ‚úÖ Works for both local file uploads and Google Drive uploads

## Previous Features (Earlier October 14, 2025)
- ‚úÖ Added scrollable upload status box showing up to 10 files with individual progress bars
- ‚úÖ Implemented multi-file upload support (drag & drop or browse multiple PDFs)
- ‚úÖ Created real-time progress tracking with thin loading bars that fill during processing
- ‚úÖ Added visual status indicators: light green background/green border for success, light red/red border for errors
- ‚úÖ Built static summary bar showing uploaded/completed/error counts
- ‚úÖ Display filename for each file being processed
- ‚úÖ Added "Copy All IDs" button to dropdown for bulk document ID copying
- ‚úÖ Enhanced dropdown to display filename, document ID (shortened), and upload timestamp
- ‚úÖ Increased dropdown width to 420px to prevent horizontal scrolling
- ‚úÖ Fixed error handling for legacy files in localStorage missing ID/timestamp fields
- ‚úÖ Fixed critical JavaScript ID mismatch bug (archive-close button) that crashed the app
- ‚úÖ Fixed CSS specificity issue preventing archive modal from closing
- ‚úÖ Implemented persistent duplicate detection using localStorage (survives page refreshes)
- ‚úÖ Complete frontend rebuild with modern drag-and-drop UI (index.html, style.css, script.js)
- ‚úÖ Fixed /query endpoint to accept JSON body (QueryRequest model with document_id and question)
- ‚úÖ Integrated chat interface that tracks uploaded document_id and enables Q&A
- ‚úÖ Added clipboard auto-copy for document IDs after upload
- ‚úÖ Fixed static file serving with proper /static/ mount paths
- ‚úÖ Added cache control headers to prevent browser caching issues
- ‚úÖ Removed duplicate Pydantic import and cleaned up code structure

# User Preferences

Preferred communication style: Simple, everyday language.

# System Architecture

## Frontend Architecture
- **Interface**: Single-page application with drag-and-drop PDF upload
- **Design**: Clean, modern UI with brain emoji branding (üß† AXIS MIND)
- **Upload Flow**: Converts PDF to base64 ‚Üí sends to /upload-base64 ‚Üí displays document_id and chunk count
- **Chat Flow**: Stores document_id ‚Üí sends questions with document_id to /query ‚Üí displays GPT answers
- **Features**: Auto-clipboard copy, Enter key support, disabled button during processing

## Backend Architecture
- **Framework**: FastAPI with async/await patterns for handling file uploads
- **Runtime**: Python with uvicorn ASGI server
- **Design Pattern**: Stateless API - frontend tracks document_id, backend queries Pinecone

## Document Processing Pipeline
- **PDF Parsing**: PyPDF2 library extracts text from uploaded PDF files
- **Text Chunking**: LangChain's RecursiveCharacterTextSplitter breaks documents into overlapping chunks (1000 chars with 200 char overlap)
- **Rationale**: Overlapping chunks preserve context across boundaries, improving retrieval quality

## Vector Storage Strategy
- **Database**: Pinecone vector database (index: "mbti-knowledge")
- **Purpose**: Stores document embeddings for semantic search and retrieval
- **Design Choice**: Cloud-hosted vector DB chosen for scalability and managed infrastructure
- **Query Strategy**: Filters by doc_id to retrieve only chunks from specified document

## Embedding Generation
- **Provider**: OpenAI API (text-embedding-ada-002 model)
- **Integration**: Direct OpenAI client usage (not through LangChain)
- **Performance**: Batch processing all embeddings before upserting to Pinecone

## API Structure
- **Upload Binary**: `POST /upload` - Accepts multipart/form-data PDF files
- **Upload Base64**: `POST /upload-base64` - Accepts JSON with pdf_base64 and filename (for ChatGPT integration)
- **Query**: `POST /query` - Accepts JSON with document_id and question (Pydantic QueryRequest model)
- **Frontend**: `GET /` - Serves index.html with cache control headers
- **Static Files**: `/static/*` - Serves CSS, JS, and other static assets
- **Docs**: `GET /docs` - Built-in FastAPI Swagger UI documentation
- **Response Format**: JSONResponse for standardized API responses
- **CORS**: Enabled for all origins

## Configuration Management
- **Environment Variables**: Replit Secrets for API keys (OPENAI_API_KEY, PINECONE_API_KEY, PINECONE_INDEX)
- **Client Initialization**: Lazy initialization pattern with helper functions that check for API keys before creating clients
- **Port**: 5000 (configurable via PORT env var)

# File Structure

```
/
‚îú‚îÄ‚îÄ main.py              # FastAPI backend with all endpoints
‚îú‚îÄ‚îÄ index.html           # Frontend HTML with upload and chat UI
‚îú‚îÄ‚îÄ style.css            # Complete styling (base + upload + chat)
‚îú‚îÄ‚îÄ script.js            # Upload + chat functionality with document_id tracking
‚îú‚îÄ‚îÄ requirements.txt     # Python dependencies
‚îî‚îÄ‚îÄ replit.md           # This documentation file
```

# External Dependencies

## Vector Database
- **Pinecone**: Cloud vector database for storing and querying embeddings
- **Index Name**: "mbti-knowledge" (suggests MBTI personality-related knowledge base)
- **Authentication**: API key-based

## AI/ML Services
- **OpenAI API**: Text embedding (text-embedding-ada-002) and GPT-3.5-turbo for Q&A
- **Authentication**: API key-based via Replit Secrets
- **Error Handling**: Comprehensive try/catch blocks with debug logging

## Document Processing
- **PyPDF2**: PDF parsing and text extraction
- **LangChain**: Text splitting utilities (RecursiveCharacterTextSplitter)

## Web Framework
- **FastAPI**: Async web framework for REST API
- **Uvicorn**: ASGI server for running the application
- **Pydantic**: Data validation with QueryRequest model

## Deployment
- **Platform**: Replit with 24/7 uptime capability
- **Run Command**: `python main.py`
- **Port**: 5000
- **Secrets Required**: OPENAI_API_KEY, PINECONE_API_KEY, PINECONE_INDEX
- **Production URL**: https://axis-of-mind.replit.app
